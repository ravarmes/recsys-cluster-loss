
from sklearn.metrics.cluster import adjusted_rand_score
from sklearn.metrics.cluster import rand_score
from sklearn.metrics.cluster import adjusted_mutual_info_score
from sklearn.metrics.cluster import fowlkes_mallows_score
from sklearn.metrics.cluster import contingency_matrix
from sklearn.metrics.cluster import pair_confusion_matrix

G_Books_Age =        {1: [254, 638, 882, 929, 1155, 1161, 1214, 1248, 1249, 1254, 1262, 1279, 1331, 1368, 1409, 1412, 1485, 1517, 1535, 1558, 1585, 1719, 1791, 1848, 1923, 2030, 2033, 2041, 2090, 2106, 2110, 2134, 2135, 2136, 2189, 2238, 2276, 2287, 2288, 2296, 2337, 2349, 2354, 2358, 2363, 2389, 2411, 2439, 2462, 2545, 2597, 2630, 2644, 2651, 2653, 2766, 2891, 3145, 3167, 3363, 4017, 5037, 6073, 6532, 6543, 6563, 6575, 6789, 7125, 7286, 7346, 7841, 8066, 8067, 8454, 8681, 8930, 9177, 9908, 10447, 10560, 11224, 11245, 11657, 11676, 11724, 11944, 12489, 13518, 13666, 14744, 15408, 15834, 15957, 16795, 16916, 17859, 19233, 19664, 20060, 20106, 20180, 21356, 21484, 21659, 23571, 23768, 23872, 24194, 25131, 25395, 25601, 25919, 26057, 26517, 26538, 26883, 29209], 2: [1167, 1184, 1211, 1261, 1297, 1372, 1399, 1424, 1435, 1466, 1499, 1548, 1597, 1652, 1688, 1733, 1812, 1830, 1869, 1898, 1901, 1903, 1990, 2009, 2036, 2046, 2139, 2222, 2255, 2295, 2313, 2385, 2404, 2406, 2437, 2466, 2549, 2622, 2678, 2688, 2719, 2977, 3373, 4221, 4785, 4795, 4938, 5582, 5899, 5903, 6115, 6242, 6251, 6772, 7283, 7915, 8187, 8245, 8253, 8680, 8734, 9856, 10314, 10819, 11718, 11788, 12100, 12982, 13080, 13273, 13551, 13582, 13850, 14456, 15049, 16504, 16599, 16718, 16966, 17003, 17950, 18203, 19711, 20680, 21014, 21031, 21364, 21404, 21576, 22094, 23902, 24186, 25409, 25410, 26371, 26535, 27472, 27740, 28634, 29259, 29526], 3: [1131, 1178, 1192, 1219, 1294, 1348, 1376, 1436, 1467, 1554, 1596, 1608, 1660, 1674, 1706, 1725, 1790, 1805, 1838, 1863, 1881, 1891, 1928, 2010, 2012, 2024, 2084, 2103, 2132, 2152, 2179, 2197, 2281, 2326, 2333, 2399, 2415, 2461, 2470, 2481, 2552, 2559, 2589, 3371, 3827, 5027, 6323, 7158, 9226, 12154, 12784, 13552, 13664, 13935, 14422, 14768, 15418, 15602, 16246, 16634, 18082, 19493, 20172, 20462, 21011, 22074, 22252, 22625, 22936, 23547, 23933, 25966, 25981, 26240, 26620, 26621, 27091, 28177, 28204, 28594, 28647]}
G_Books_All =        {1: [254, 638, 882, 929, 1131, 1155, 1161, 1178, 1192, 1214, 1219, 1248, 1249, 1254, 1262, 1279, 1294, 1331, 1348, 1368, 1376, 1409, 1412, 1436, 1467, 1485, 1517, 1535, 1554, 1558, 1585, 1596, 1608, 1660, 1674, 1706, 1719, 1725, 1790, 1791, 1805, 1838, 1848, 1863, 1881, 1891, 1923, 1928, 2010, 2012, 2024, 2030, 2033, 2041, 2084, 2090, 2103, 2106, 2110, 2132, 2134, 2135, 2136, 2152, 2179, 2189, 2197, 2238, 2281, 2287, 2288, 2296, 2326, 2333, 2337, 2349, 2354, 2358, 2363, 2389, 2399, 2411, 2415, 2439, 2461, 2462, 2470, 2481, 2545, 2552, 2559, 2589, 2597, 2630, 2644, 2651, 2653, 2766, 2891, 3145, 3167, 3363, 3371, 3827, 4017, 5027, 5037, 6073, 6323, 6532, 6563, 6575, 6789, 7125, 7158, 7286, 7346, 7841, 8066, 8067, 8454, 8681, 8930, 9177, 9226, 9908, 10447, 10560, 11224, 11245, 11657, 11724, 11944, 12154, 12489, 12784, 13518, 13552, 13664, 13666, 13935, 14422, 14744, 14768, 15408, 15418, 15602, 15834, 15957, 16246, 16634, 16795, 16916, 17859, 18082, 19233, 19493, 19664, 20060, 20106, 20172, 20180, 20462, 21011, 21356, 21484, 21659, 22074, 22252, 22625, 22936, 23547, 23571, 23768, 23872, 23933, 24194, 25131, 25395, 25601, 25919, 25966, 25981, 26057, 26240, 26517, 26538, 26620, 26621, 26883, 27091, 28177, 28204, 28594, 28647, 29209], 2: [11676], 3: [1167, 1184, 1211, 1261, 1297, 1372, 1399, 1424, 1435, 1466, 1499, 1548, 1597, 1652, 1688, 1733, 1812, 1830, 1869, 1898, 1901, 1903, 1990, 2009, 2036, 2046, 2139, 2222, 2255, 2276, 2295, 2313, 2385, 2404, 2406, 2437, 2466, 2549, 2622, 2678, 2688, 2719, 2977, 3373, 4221, 4785, 4795, 4938, 5582, 5899, 5903, 6115, 6242, 6251, 6543, 6772, 7283, 7915, 8187, 8245, 8253, 8680, 8734, 9856, 10314, 10819, 11718, 11788, 12100, 12982, 13080, 13273, 13551, 13582, 13850, 14456, 15049, 16504, 16599, 16718, 16966, 17003, 17950, 18203, 19711, 20680, 21014, 21031, 21364, 21404, 21576, 22094, 23902, 24186, 25409, 25410, 26371, 26535, 27472, 27740, 28634, 29259, 29526]}
G_Books_AllAndLoss = {1: [254, 882, 929, 1131, 1161, 1178, 1192, 1214, 1219, 1254, 1294, 1331, 1348, 1368, 1376, 1412, 1436, 1467, 1485, 1535, 1554, 1558, 1596, 1608, 1660, 1674, 1706, 1719, 1725, 1790, 1805, 1838, 1848, 1863, 1881, 1891, 1923, 1928, 2010, 2012, 2024, 2030, 2033, 2041, 2084, 2103, 2106, 2110, 2132, 2134, 2135, 2152, 2179, 2189, 2197, 2281, 2287, 2288, 2296, 2326, 2333, 2349, 2354, 2358, 2399, 2411, 2415, 2439, 2461, 2470, 2481, 2552, 2559, 2589, 2597, 2644, 2651, 2653, 3145, 3167, 3363, 3371, 3373, 3827, 4017, 5027, 5037, 6073, 6323, 6532, 6789, 7125, 7158, 7286, 7841, 8066, 8067, 8454, 8681, 9177, 9226, 9908, 10447, 10819, 11224, 11657, 11724, 11944, 12154, 12489, 12784, 13518, 13552, 13664, 13935, 14422, 14744, 14768, 15408, 15418, 15602, 15834, 15957, 16246, 16634, 16795, 16916, 17859, 18082, 19233, 19493, 19664, 20106, 20172, 20180, 20462, 21011, 21364, 21659, 22074, 22252, 22625, 22936, 23547, 23571, 23933, 24194, 25395, 25601, 25919, 25966, 25981, 26057, 26240, 26538, 26620, 26621, 27091, 28177, 28204, 28594, 28647, 29209], 2: [11676], 3: [638, 1155, 1167, 1184, 1211, 1248, 1249, 1261, 1262, 1279, 1297, 1372, 1399, 1409, 1424, 1435, 1466, 1499, 1517, 1548, 1585, 1597, 1652, 1688, 1733, 1791, 1812, 1830, 1869, 1898, 1901, 1903, 1990, 2009, 2036, 2046, 2090, 2136, 2139, 2222, 2238, 2255, 2276, 2295, 2313, 2337, 2363, 2385, 2389, 2404, 2406, 2437, 2462, 2466, 2545, 2549, 2622, 2630, 2678, 2688, 2719, 2766, 2891, 2977, 4221, 4785, 4795, 4938, 5582, 5899, 5903, 6115, 6242, 6251, 6543, 6563, 6575, 6772, 7283, 7346, 7915, 8187, 8245, 8253, 8680, 8734, 8930, 9856, 10314, 10560, 11245, 11718, 11788, 12100, 12982, 13080, 13273, 13551, 13582, 13666, 13850, 14456, 15049, 16504, 16599, 16718, 16966, 17003, 17950, 18203, 19711, 20060, 20680, 21014, 21031, 21356, 21404, 21484, 21576, 22094, 23768, 23872, 23902, 24186, 25131, 25409, 25410, 26371, 26517, 26535, 26883, 27472, 27740, 28634, 29259, 29526]}
G_Books_Loss =       {1: [882, 1167, 1178, 1184, 1214, 1249, 1279, 1376, 1435, 1436, 1558, 1596, 1674, 1706, 1898, 2012, 2036, 2106, 2139, 2222, 2255, 2288, 2295, 2313, 2385, 2406, 2589, 2766, 2977, 3145, 3167, 3363, 3371, 3373, 4017, 5027, 5037, 6073, 6251, 6563, 6575, 6772, 7158, 7283, 7286, 7841, 7915, 8066, 8454, 8681, 9908, 10314, 10447, 10819, 11224, 11676, 11788, 11944, 12489, 13518, 13552, 13850, 15418, 15602, 16246, 16599, 16634, 16795, 17003, 19233, 19493, 19664, 20106, 20462, 21014, 21031, 22074, 23547, 23902, 23933, 24194, 25410, 25601, 25966, 25981, 26535, 26621, 26883, 28177, 28204, 29209], 2: [6789, 15957, 21364, 26538], 3: [254, 638, 929, 1131, 1155, 1161, 1192, 1211, 1219, 1248, 1254, 1261, 1262, 1294, 1297, 1331, 1348, 1368, 1372, 1399, 1409, 1412, 1424, 1466, 1467, 1485, 1499, 1517, 1535, 1548, 1554, 1585, 1597, 1608, 1652, 1660, 1688, 1719, 1725, 1733, 1790, 1791, 1805, 1812, 1830, 1838, 1848, 1863, 1869, 1881, 1891, 1901, 1903, 1923, 1928, 1990, 2009, 2010, 2024, 2030, 2033, 2041, 2046, 2084, 2090, 2103, 2110, 2132, 2134, 2135, 2136, 2152, 2179, 2189, 2197, 2238, 2276, 2281, 2287, 2296, 2326, 2333, 2337, 2349, 2354, 2358, 2363, 2389, 2399, 2404, 2411, 2415, 2437, 2439, 2461, 2462, 2466, 2470, 2481, 2545, 2549, 2552, 2559, 2597, 2622, 2630, 2644, 2651, 2653, 2678, 2688, 2719, 2891, 3827, 4221, 4785, 4795, 4938, 5582, 5899, 5903, 6115, 6242, 6323, 6532, 6543, 7125, 7346, 8067, 8187, 8245, 8253, 8680, 8734, 8930, 9177, 9226, 9856, 10560, 11245, 11657, 11718, 11724, 12100, 12154, 12784, 12982, 13080, 13273, 13551, 13582, 13664, 13666, 13935, 14422, 14456, 14744, 14768, 15049, 15408, 15834, 16504, 16718, 16916, 16966, 17859, 17950, 18082, 18203, 19711, 20060, 20172, 20180, 20680, 21011, 21356, 21404, 21484, 21576, 21659, 22094, 22252, 22625, 22936, 23571, 23768, 23872, 24186, 25131, 25395, 25409, 25919, 26057, 26240, 26371, 26517, 26620, 27091, 27472, 27740, 28594, 28634, 28647, 29259, 29526]}
G_Books_NR =         {1: [1131, 1211, 1248, 1424, 1435, 1548, 1585, 1674, 1733, 1848, 1903, 2024, 2030, 2033, 2103, 2110, 2179, 2288, 2313, 2337, 2363, 4017, 6242, 6251, 6543, 6575, 7346, 8454, 13552, 16795, 21014, 23872, 23902, 25981, 28177, 28634], 2: [11676], 3: [254, 638, 882, 929, 1155, 1161, 1167, 1178, 1184, 1192, 1214, 1219, 1249, 1254, 1261, 1262, 1279, 1294, 1297, 1331, 1348, 1368, 1372, 1376, 1399, 1409, 1412, 1436, 1466, 1467, 1485, 1499, 1517, 1535, 1554, 1558, 1596, 1597, 1608, 1652, 1660, 1688, 1706, 1719, 1725, 1790, 1791, 1805, 1812, 1830, 1838, 1863, 1869, 1881, 1891, 1898, 1901, 1923, 1928, 1990, 2009, 2010, 2012, 2036, 2041, 2046, 2084, 2090, 2106, 2132, 2134, 2135, 2136, 2139, 2152, 2189, 2197, 2222, 2238, 2255, 2276, 2281, 2287, 2295, 2296, 2326, 2333, 2349, 2354, 2358, 2385, 2389, 2399, 2404, 2406, 2411, 2415, 2437, 2439, 2461, 2462, 2466, 2470, 2481, 2545, 2549, 2552, 2559, 2589, 2597, 2622, 2630, 2644, 2651, 2653, 2678, 2688, 2719, 2766, 2891, 2977, 3145, 3167, 3363, 3371, 3373, 3827, 4221, 4785, 4795, 4938, 5027, 5037, 5582, 5899, 5903, 6073, 6115, 6323, 6532, 6563, 6772, 6789, 7125, 7158, 7283, 7286, 7841, 7915, 8066, 8067, 8187, 8245, 8253, 8680, 8681, 8734, 8930, 9177, 9226, 9856, 9908, 10314, 10447, 10560, 10819, 11224, 11245, 11657, 11718, 11724, 11788, 11944, 12100, 12154, 12489, 12784, 12982, 13080, 13273, 13518, 13551, 13582, 13664, 13666, 13850, 13935, 14422, 14456, 14744, 14768, 15049, 15408, 15418, 15602, 15834, 15957, 16246, 16504, 16599, 16634, 16718, 16916, 16966, 17003, 17859, 17950, 18082, 18203, 19233, 19493, 19664, 19711, 20060, 20106, 20172, 20180, 20462, 20680, 21011, 21031, 21356, 21364, 21404, 21484, 21576, 21659, 22074, 22094, 22252, 22625, 22936, 23547, 23571, 23768, 23933, 24186, 24194, 25131, 25395, 25409, 25410, 25601, 25919, 25966, 26057, 26240, 26371, 26517, 26535, 26538, 26620, 26621, 26883, 27091, 27472, 27740, 28204, 28594, 28647, 29209, 29259, 29526]}

Labels_Books_Age          = [0, 0, 0, 0, 2, 0, 0, 1, 2, 1, 2, 1, 0, 2, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 0, 1, 2, 1, 0, 0, 1, 1, 2, 1, 2, 0, 1, 0, 0, 1, 2, 0, 0, 2, 1, 2, 1, 2, 2, 1, 2, 0, 2, 1, 2, 0, 2, 1, 1, 2, 0, 2, 1, 2, 2, 1, 1, 1, 0, 2, 1, 1, 2, 2, 2, 0, 0, 1, 0, 1, 2, 0, 2, 0, 0, 2, 0, 0, 0, 1, 2, 2, 0, 2, 1, 0, 1, 0, 2, 0, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 0, 1, 0, 2, 1, 1, 0, 2, 1, 0, 2, 0, 1, 2, 2, 0, 1, 2, 2, 2, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 1, 2, 0, 1, 1, 1, 1, 2, 0, 1, 1, 1, 0, 1, 1, 1, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 2, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 2, 0, 2, 1, 1, 1, 0, 1, 2, 1, 2, 0, 1, 2, 2, 1, 0, 2, 1, 0, 2, 2, 0, 0, 2, 1, 1, 2, 1, 0, 0, 1, 1, 0, 1, 2, 1, 0, 2, 0, 1, 0, 0, 2, 0, 2, 1, 2, 1, 1, 0, 1, 1, 0, 1, 0, 2, 1, 2, 2, 2, 2, 0, 0, 0, 1, 2, 1, 0, 0, 0, 1, 1, 0, 0, 2, 2, 0, 2, 1, 0, 1, 0, 2, 2, 0, 2, 1, 1, 2, 2, 2, 1, 2, 0, 1, 1]
Labels_Books_All          = [1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0]
Labels_Books_AllAndLoss   = [1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0]
Labels_Books_Loss         = [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 2, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1]
Labels_Books_NR           = [0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0]

'''
sklearn.metrics.cluster.adjusted_rand_score: Rand index
Given the knowledge of the ground truth class assignments labels_true and our clustering algorithm assignments of the same 
samples labels_pred, the (adjusted or unadjusted) Rand index is a function that measures the similarity of the two assignments, 
ignoring permutations
'''
print('--------------------------------------------------------------------------')
print('sklearn.metrics.cluster: adjusted_rand_score')
print('--------------------------------------------------------------------------')
print('Labels_Books_Age vs Labels_Books_Loss:          ', adjusted_rand_score(Labels_Books_Age, Labels_Books_Loss))
print('Label_Books_All vs Labels_Books_Loss:           ', adjusted_rand_score(Labels_Books_All, Labels_Books_Loss))
print('Labels_Books_AllAndLoss vs Labels_Books_Loss:   ', adjusted_rand_score(Labels_Books_AllAndLoss, Labels_Books_Loss))
print('Labels_Books_NR vs Labels_Books_Loss:           ', adjusted_rand_score(Labels_Books_NR, Labels_Books_Loss))
print('Labels_Books_Loss vs Labels_Books_Loss:         ', adjusted_rand_score(Labels_Books_Loss, Labels_Books_Loss))
print('--------------------------------------------------------------------------')

print('--------------------------------------------------------------------------')
print('sklearn.metrics.cluster: rand_score')
print('--------------------------------------------------------------------------')
print('Labels_Books_Age vs Labels_Books_Loss:          ', rand_score(Labels_Books_Age, Labels_Books_Loss))
print('Label_Books_All vs Labels_Books_Loss:           ', rand_score(Labels_Books_All, Labels_Books_Loss))
print('Labels_Books_AllAndLoss vs Labels_Books_Loss:   ', rand_score(Labels_Books_AllAndLoss, Labels_Books_Loss))
print('Labels_Books_NR vs Labels_Books_Loss:           ', rand_score(Labels_Books_NR, Labels_Books_Loss))
print('Labels_Books_Loss vs Labels_Books_Loss:         ', rand_score(Labels_Books_Loss, Labels_Books_Loss))
print('--------------------------------------------------------------------------')

'''
sklearn.metrics.cluster.adjusted_mutual_info_score: Mutual Information based scores
Given the knowledge of the ground truth class assignments labels_true and our clustering algorithm assignments of the same 
samples labels_pred, the Mutual Information is a function that measures the agreement of the two assignments, ignoring permutations.
'''
print()
print('--------------------------------------------------------------------------')
print('sklearn.metrics.cluster: adjusted_mutual_info_score')
print('--------------------------------------------------------------------------')
print('Labels_Books_Age vs Labels_Books_Loss:          ', adjusted_mutual_info_score(Labels_Books_Age, Labels_Books_Loss))
print('Label_Books_All vs Labels_Books_Loss:           ', adjusted_mutual_info_score(Labels_Books_All, Labels_Books_Loss))
print('Labels_Books_AllAndLoss vs Labels_Books_Loss:   ', adjusted_mutual_info_score(Labels_Books_AllAndLoss, Labels_Books_Loss))
print('Labels_Books_NR vs Labels_Books_Loss:           ', adjusted_mutual_info_score(Labels_Books_NR, Labels_Books_Loss))
print('Labels_Books_Loss vs Labels_Books_Loss:         ', adjusted_mutual_info_score(Labels_Books_Loss, Labels_Books_Loss))
print('--------------------------------------------------------------------------')

'''
sklearn.metrics.cluster.fowlkes_mallows_score: Fowlkes-Mallows scores
The Fowlkes-Mallows index (sklearn.metrics.fowlkes_mallows_score) can be used when the ground truth class assignments of the 
samples is known. The Fowlkes-Mallows score FMI is defined as the geometric mean of the pairwise precision and recall.
'''
print()
print('--------------------------------------------------------------------------')
print('sklearn.metrics.cluster: fowlkes_mallows_score')
print('--------------------------------------------------------------------------')
print('Labels_Books_Age vs Labels_Books_Loss:          ', fowlkes_mallows_score(Labels_Books_Age, Labels_Books_Loss))
print('Label_Books_All vs Labels_Books_Loss:           ', fowlkes_mallows_score(Labels_Books_All, Labels_Books_Loss))
print('Labels_Books_AllAndLoss vs Labels_Books_Loss:   ', fowlkes_mallows_score(Labels_Books_AllAndLoss, Labels_Books_Loss))
print('Labels_Books_NR vs Labels_Books_Loss:           ', fowlkes_mallows_score(Labels_Books_NR, Labels_Books_Loss))
print('Labels_Books_Loss vs Labels_Books_Loss:         ', fowlkes_mallows_score(Labels_Books_Loss, Labels_Books_Loss))
print('--------------------------------------------------------------------------')

'''
sklearn.metrics.cluster.contingency_matrix: Contingency Matrix
Contingency matrix (sklearn.metrics.cluster.contingency_matrix) reports the intersection cardinality for every 
true/predicted cluster pair.
'''
print()
print('--------------------------------------------------------------------------')
print('contingency_matrix')
cont_matrix = contingency_matrix(Labels_Books_Age, Labels_Books_Loss)
print(cont_matrix)
print('--------------------------------------------------------------------------')

'''
sklearn.metrics.cluster.pair_confusion_matrix: Pair Confusion Matrix
The pair confusion matrix is a 2x2
between two clusterings computed by considering all pairs of samples and counting pairs that are assigned 
into the same or into different clusters under the true and predicted clusterings.
'''
print()
print('--------------------------------------------------------------------------')
print('pair_confusion_matrix')
print('--------------------------------------------------------------------------')
print(pair_confusion_matrix(Labels_Books_Age, Labels_Books_Loss))
print('--------------------------------------------------------------------------')